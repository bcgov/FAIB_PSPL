---
title: "Raster Point Load to PostgreSQL"
author: "D. Waddell"
date: "`r Sys.Date()`"
output: md_document
---

## Import from GDB to PostgreSQL



Start: `r Sys.time()`

```{r read_data}


year <- '2022'

library(sf)

library(RPostgreSQL)


# set up for load to PostgreSQL
schema <- paste0('msyt_',year)
opt <- paste0("-c search_path=",schema)
user_name <- 'postgres'
database <- 'msyt'
con <- dbConnect('PostgreSQL',dbname=database,user=user_name,options=opt)


# this is where the unzipped files are placed locally
local_gdb_folder <- paste0(substr(getwd(),1,1),':/data/data_projects/AR2022/PSPL/gdb_test2')

# build list of the PSPL gdbs
# list of gdb files to process
f_list <- list.files(local_gdb_folder,full.names = TRUE)
num_gdb = length(f_list)  #number of files to process



```




## process each gdb 

- Read each GDB
- export to PostgreSQL


## Load via Terra

Fails as spatVect can't be exported to PostgreSQL  

Error in (function (classes, fdef, mtable)  :  
  unable to find an inherited method for function ‘dbWriteTable’ for signature   ‘"PostgreSQLConnection", "character", "SpatVector"’  

```{r load_terra, eval = FALSE}

terra_gdb_load <- function(pf,n){

n <- 1
pf <- f_list[2]

t_name <- tools::file_path_sans_ext(basename(pf))
  
  # read the point file
  point_set <- vect(pf)
  

  tab_name <- paste0('pspl_terra_unit',n)
  
  dbWriteTable(con,tab_name,point_set,row.names=FALSE,overwrite=TRUE)
  
  
  

}

```


```{r load_sf, eval=FALSE}

s1 <- sf::st_read(f_list[1])

tab_name <- paste0('pspl_sf_unit',1)
dbWriteTable(con,tab_name,s1,row.names=FALSE,overwrite=TRUE)


```



## Load using sf::gdal_utils

This will bring any NULL values in the GDB as actual NULL in PostgreSQL.


```{r load_gdal_utils, eval = TRUE}

gdal_utils_gdb_load <- function(pf,n){

  # n <- 1
  # pf <- f_list[1]
  
  # PostgreSQL connection settings
  # schema is not defined
  dest <- c("PG:dbname=msyt user=results")
  
  gdb_fc <- tools::file_path_sans_ext(basename(pf))
  
  # give new layer name the schema name 
  new_layer <- paste0('msyt_',year,'.pspl_gdal_util_unit',n)
  
  #sel_query <- paste0('select id_tag,at_si,ba_si,bg_si,bl_si,cw_si,dr_si,ep_si,fd_si,hm_si,hw_si,lt_si,lw_si,pa_si,pl_si,pw_si,py_si,sb_si,se_si,ss_si,sw_si,sx_si,yc_si from ',gdb_fc)
  #'-sql', sel_query,
  
  gdal_utils(
    util="vectortranslate",
    source=pf,
    dest,
    options=
      c('-a_srs','EPSG:3005',
        '-nln',new_layer, 
        '-gt','20000',
		    '-lco', 'GEOMETRY_NAME=wkb_geometry',
        '-overwrite',
		    '-sql', sel_query
        )
    )
  

}

```

ogr2ogr -a_srs EPSG:3005 -nln test1 -gt 200000 --config PG_USE_COPY YES -lco GEOMETRY_NAME= wkb_geometry -f PostgreSQL PG:dbname=msyt user=results Site_Prod_100_Mile_House.gdb Site_Prod_100_Mile_House

## ogr2ogr import to PostgreSQL  

- ogr2ogr -a_srs EPSG:3005 -nln test1 -gt 200000 --config PG_USE_COPY YES -lco GEOMETRY_NAME=wkb_geometry -f PostgreSQL PG:"dbname=msyt user=results" Site_Prod_100_Mile_House.gdb Site_Prod_100_Mile_House

Note: If you get the following message when doing a psql> \d table   
ERROR:  column c.relhasoids does not exist  
Your client is wrong.  
Change to client that matches your PostreSQL version.


```{r}


#dest <- c("PG:dbname='msyt' user='results'")

select <- "id_tag,at_si,ba_si,bg_si,bl_si,cw_si,dr_si,ep_si,fd_si,hm_si,hw_si,lt_si,lw_si,pa_si,pl_si,pw_si,py_si,sb_si,se_si,ss_si,sw_si,sx_si,yc_si"

ogr_load <- function(pf,n){
  
  
    # pf = GDB full name
  
  # give new layer name the schema name 
  new_layer <- paste0('msyt_',year,'.pspl_ogr2ogr_unit',n)
  gdb_fc <- tools::file_path_sans_ext(basename(pf))  
  
  ogr1 <- paste0("-a_srs EPSG:3005 -gt 100000 -select ",select,' ')
  ogr2 <- paste0("-f PostgreSQL \"PG:dbname='msyt' user='results'\" -nln  ")
  ogr_cmd <- paste0(ogr1,ogr2,new_layer,' ',pf,' ',gdb_fc,' -lco ', 'GEOMETRY_NAME=wkb_geometry',' -overwrite')

  system2("ogr2ogr",args=ogr_cmd,wait=TRUE,stderr=TRUE)
  
}


```


```{r load_all_units}




# creates unit1 .. unitxx depending on the number of GDBs
  # unit1 does NOT refer to tsa 01
  # it is simply a reference number
if(length(f_list) ==0 ) { print("file list EMPTY")}

# initialize the counter
n <- 1


#process the file list
for(f in f_list){
      
  a <- gdal_utils_gdb_load(f,n)
  b <- ogr_load(f,n)
  n <- n + 1
      
}



```


## Test compare

Union the 2 tables from each method.  
If the row count does not inceras, the tables are exactly the same. 


```{r ending}

a1 <- 'pspl_gdal_util_unit1'
a2 <- 'pspl_gdal_util_unit2'
b1 <- 'pspl_ogr2ogr_unit1'
b2 <- 'pspl_ogr2ogr_unit2'

q1 <- paste0('create table u1 as select * from ',a1,' union select * from ',b1)
q2 <- paste0('create table u2 as select * from ',a2,' union select * from ',b2)

dbExecute(con, 'drop table if exists u1')
dbExecute(con, 'drop table if exists u2')

dbExecute(con,q1)
dbExecute(con,q2)

a1_cnt <- dbGetQuery(con,'select count(*) from pspl_gdal_util_unit1')
b1_cnt <- dbGetQuery(con,'select count(*) from pspl_ogr2ogr_unit1')
u1_cnt <- dbGetQuery(con,'select count(*) from u1')

rep1 <- data.frame('table' = c('pspl_gdal_util_unit1','pspl_ogr2ogr_unit1','union'), 'n' = c(a1_cnt$count,b1_cnt$count,u1_cnt$count))

dbExecute(con, 'drop table if exists u1')
dbExecute(con, 'drop table if exists u2')

knitr::kable(rep1,format="markdown")


dbDisconnect(con)


```

Table 1.  If all the numbers are the same, then the union indicates taht the tables are exactly the same.  


End: `r Sys.time()`


